{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.utils.data as data_utils\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv('../data/train.csv', index_col='ID_code')\n",
    "test=pd.read_csv('../data/test.csv', index_col='ID_code')\n",
    "submission=pd.read_csv('../data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200000, 201)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID_code</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train_0</th>\n",
       "      <td>0</td>\n",
       "      <td>8.9255</td>\n",
       "      <td>-6.7863</td>\n",
       "      <td>11.9081</td>\n",
       "      <td>5.0930</td>\n",
       "      <td>11.4607</td>\n",
       "      <td>-9.2834</td>\n",
       "      <td>5.1187</td>\n",
       "      <td>18.6266</td>\n",
       "      <td>-4.9200</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4354</td>\n",
       "      <td>3.9642</td>\n",
       "      <td>3.1364</td>\n",
       "      <td>1.6910</td>\n",
       "      <td>18.5227</td>\n",
       "      <td>-2.3978</td>\n",
       "      <td>7.8784</td>\n",
       "      <td>8.5635</td>\n",
       "      <td>12.7803</td>\n",
       "      <td>-1.0914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_1</th>\n",
       "      <td>0</td>\n",
       "      <td>11.5006</td>\n",
       "      <td>-4.1473</td>\n",
       "      <td>13.8588</td>\n",
       "      <td>5.3890</td>\n",
       "      <td>12.3622</td>\n",
       "      <td>7.0433</td>\n",
       "      <td>5.6208</td>\n",
       "      <td>16.5338</td>\n",
       "      <td>3.1468</td>\n",
       "      <td>...</td>\n",
       "      <td>7.6421</td>\n",
       "      <td>7.7214</td>\n",
       "      <td>2.5837</td>\n",
       "      <td>10.9516</td>\n",
       "      <td>15.4305</td>\n",
       "      <td>2.0339</td>\n",
       "      <td>8.1267</td>\n",
       "      <td>8.7889</td>\n",
       "      <td>18.3560</td>\n",
       "      <td>1.9518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_2</th>\n",
       "      <td>0</td>\n",
       "      <td>8.6093</td>\n",
       "      <td>-2.7457</td>\n",
       "      <td>12.0805</td>\n",
       "      <td>7.8928</td>\n",
       "      <td>10.5825</td>\n",
       "      <td>-9.0837</td>\n",
       "      <td>6.9427</td>\n",
       "      <td>14.6155</td>\n",
       "      <td>-4.9193</td>\n",
       "      <td>...</td>\n",
       "      <td>2.9057</td>\n",
       "      <td>9.7905</td>\n",
       "      <td>1.6704</td>\n",
       "      <td>1.6858</td>\n",
       "      <td>21.6042</td>\n",
       "      <td>3.1417</td>\n",
       "      <td>-6.5213</td>\n",
       "      <td>8.2675</td>\n",
       "      <td>14.7222</td>\n",
       "      <td>0.3965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_3</th>\n",
       "      <td>0</td>\n",
       "      <td>11.0604</td>\n",
       "      <td>-2.1518</td>\n",
       "      <td>8.9522</td>\n",
       "      <td>7.1957</td>\n",
       "      <td>12.5846</td>\n",
       "      <td>-1.8361</td>\n",
       "      <td>5.8428</td>\n",
       "      <td>14.9250</td>\n",
       "      <td>-5.8609</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4666</td>\n",
       "      <td>4.7433</td>\n",
       "      <td>0.7178</td>\n",
       "      <td>1.4214</td>\n",
       "      <td>23.0347</td>\n",
       "      <td>-1.2706</td>\n",
       "      <td>-2.9275</td>\n",
       "      <td>10.2922</td>\n",
       "      <td>17.9697</td>\n",
       "      <td>-8.9996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_4</th>\n",
       "      <td>0</td>\n",
       "      <td>9.8369</td>\n",
       "      <td>-1.4834</td>\n",
       "      <td>12.8746</td>\n",
       "      <td>6.6375</td>\n",
       "      <td>12.2772</td>\n",
       "      <td>2.4486</td>\n",
       "      <td>5.9405</td>\n",
       "      <td>19.2514</td>\n",
       "      <td>6.2654</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.4905</td>\n",
       "      <td>9.5214</td>\n",
       "      <td>-0.1508</td>\n",
       "      <td>9.1942</td>\n",
       "      <td>13.2876</td>\n",
       "      <td>-1.5121</td>\n",
       "      <td>3.9267</td>\n",
       "      <td>9.5031</td>\n",
       "      <td>17.9974</td>\n",
       "      <td>-8.8104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         target    var_0   var_1    var_2   var_3    var_4   var_5   var_6  \\\n",
       "ID_code                                                                      \n",
       "train_0       0   8.9255 -6.7863  11.9081  5.0930  11.4607 -9.2834  5.1187   \n",
       "train_1       0  11.5006 -4.1473  13.8588  5.3890  12.3622  7.0433  5.6208   \n",
       "train_2       0   8.6093 -2.7457  12.0805  7.8928  10.5825 -9.0837  6.9427   \n",
       "train_3       0  11.0604 -2.1518   8.9522  7.1957  12.5846 -1.8361  5.8428   \n",
       "train_4       0   9.8369 -1.4834  12.8746  6.6375  12.2772  2.4486  5.9405   \n",
       "\n",
       "           var_7   var_8   ...     var_190  var_191  var_192  var_193  \\\n",
       "ID_code                    ...                                          \n",
       "train_0  18.6266 -4.9200   ...      4.4354   3.9642   3.1364   1.6910   \n",
       "train_1  16.5338  3.1468   ...      7.6421   7.7214   2.5837  10.9516   \n",
       "train_2  14.6155 -4.9193   ...      2.9057   9.7905   1.6704   1.6858   \n",
       "train_3  14.9250 -5.8609   ...      4.4666   4.7433   0.7178   1.4214   \n",
       "train_4  19.2514  6.2654   ...     -1.4905   9.5214  -0.1508   9.1942   \n",
       "\n",
       "         var_194  var_195  var_196  var_197  var_198  var_199  \n",
       "ID_code                                                        \n",
       "train_0  18.5227  -2.3978   7.8784   8.5635  12.7803  -1.0914  \n",
       "train_1  15.4305   2.0339   8.1267   8.7889  18.3560   1.9518  \n",
       "train_2  21.6042   3.1417  -6.5213   8.2675  14.7222   0.3965  \n",
       "train_3  23.0347  -1.2706  -2.9275  10.2922  17.9697  -8.9996  \n",
       "train_4  13.2876  -1.5121   3.9267   9.5031  17.9974  -8.8104  \n",
       "\n",
       "[5 rows x 201 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train.shape)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200000, 200)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>var_9</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID_code</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>test_0</th>\n",
       "      <td>11.0656</td>\n",
       "      <td>7.7798</td>\n",
       "      <td>12.9536</td>\n",
       "      <td>9.4292</td>\n",
       "      <td>11.4327</td>\n",
       "      <td>-2.3805</td>\n",
       "      <td>5.8493</td>\n",
       "      <td>18.2675</td>\n",
       "      <td>2.1337</td>\n",
       "      <td>8.8100</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.1556</td>\n",
       "      <td>11.8495</td>\n",
       "      <td>-1.4300</td>\n",
       "      <td>2.4508</td>\n",
       "      <td>13.7112</td>\n",
       "      <td>2.4669</td>\n",
       "      <td>4.3654</td>\n",
       "      <td>10.7200</td>\n",
       "      <td>15.4722</td>\n",
       "      <td>-8.7197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_1</th>\n",
       "      <td>8.5304</td>\n",
       "      <td>1.2543</td>\n",
       "      <td>11.3047</td>\n",
       "      <td>5.1858</td>\n",
       "      <td>9.1974</td>\n",
       "      <td>-4.0117</td>\n",
       "      <td>6.0196</td>\n",
       "      <td>18.6316</td>\n",
       "      <td>-4.4131</td>\n",
       "      <td>5.9739</td>\n",
       "      <td>...</td>\n",
       "      <td>10.6165</td>\n",
       "      <td>8.8349</td>\n",
       "      <td>0.9403</td>\n",
       "      <td>10.1282</td>\n",
       "      <td>15.5765</td>\n",
       "      <td>0.4773</td>\n",
       "      <td>-1.4852</td>\n",
       "      <td>9.8714</td>\n",
       "      <td>19.1293</td>\n",
       "      <td>-20.9760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_2</th>\n",
       "      <td>5.4827</td>\n",
       "      <td>-10.3581</td>\n",
       "      <td>10.1407</td>\n",
       "      <td>7.0479</td>\n",
       "      <td>10.2628</td>\n",
       "      <td>9.8052</td>\n",
       "      <td>4.8950</td>\n",
       "      <td>20.2537</td>\n",
       "      <td>1.5233</td>\n",
       "      <td>8.3442</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.7484</td>\n",
       "      <td>10.9935</td>\n",
       "      <td>1.9803</td>\n",
       "      <td>2.1800</td>\n",
       "      <td>12.9813</td>\n",
       "      <td>2.1281</td>\n",
       "      <td>-7.1086</td>\n",
       "      <td>7.0618</td>\n",
       "      <td>19.8956</td>\n",
       "      <td>-23.1794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_3</th>\n",
       "      <td>8.5374</td>\n",
       "      <td>-1.3222</td>\n",
       "      <td>12.0220</td>\n",
       "      <td>6.5749</td>\n",
       "      <td>8.8458</td>\n",
       "      <td>3.1744</td>\n",
       "      <td>4.9397</td>\n",
       "      <td>20.5660</td>\n",
       "      <td>3.3755</td>\n",
       "      <td>7.4578</td>\n",
       "      <td>...</td>\n",
       "      <td>9.5702</td>\n",
       "      <td>9.0766</td>\n",
       "      <td>1.6580</td>\n",
       "      <td>3.5813</td>\n",
       "      <td>15.1874</td>\n",
       "      <td>3.1656</td>\n",
       "      <td>3.9567</td>\n",
       "      <td>9.2295</td>\n",
       "      <td>13.0168</td>\n",
       "      <td>-4.2108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_4</th>\n",
       "      <td>11.7058</td>\n",
       "      <td>-0.1327</td>\n",
       "      <td>14.1295</td>\n",
       "      <td>7.7506</td>\n",
       "      <td>9.1035</td>\n",
       "      <td>-8.5848</td>\n",
       "      <td>6.8595</td>\n",
       "      <td>10.6048</td>\n",
       "      <td>2.9890</td>\n",
       "      <td>7.1437</td>\n",
       "      <td>...</td>\n",
       "      <td>4.2259</td>\n",
       "      <td>9.1723</td>\n",
       "      <td>1.2835</td>\n",
       "      <td>3.3778</td>\n",
       "      <td>19.5542</td>\n",
       "      <td>-0.2860</td>\n",
       "      <td>-5.1612</td>\n",
       "      <td>7.2882</td>\n",
       "      <td>13.9260</td>\n",
       "      <td>-9.1846</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           var_0    var_1    var_2   var_3    var_4   var_5   var_6    var_7  \\\n",
       "ID_code                                                                        \n",
       "test_0   11.0656   7.7798  12.9536  9.4292  11.4327 -2.3805  5.8493  18.2675   \n",
       "test_1    8.5304   1.2543  11.3047  5.1858   9.1974 -4.0117  6.0196  18.6316   \n",
       "test_2    5.4827 -10.3581  10.1407  7.0479  10.2628  9.8052  4.8950  20.2537   \n",
       "test_3    8.5374  -1.3222  12.0220  6.5749   8.8458  3.1744  4.9397  20.5660   \n",
       "test_4   11.7058  -0.1327  14.1295  7.7506   9.1035 -8.5848  6.8595  10.6048   \n",
       "\n",
       "          var_8   var_9   ...     var_190  var_191  var_192  var_193  var_194  \\\n",
       "ID_code                   ...                                                   \n",
       "test_0   2.1337  8.8100   ...     -2.1556  11.8495  -1.4300   2.4508  13.7112   \n",
       "test_1  -4.4131  5.9739   ...     10.6165   8.8349   0.9403  10.1282  15.5765   \n",
       "test_2   1.5233  8.3442   ...     -0.7484  10.9935   1.9803   2.1800  12.9813   \n",
       "test_3   3.3755  7.4578   ...      9.5702   9.0766   1.6580   3.5813  15.1874   \n",
       "test_4   2.9890  7.1437   ...      4.2259   9.1723   1.2835   3.3778  19.5542   \n",
       "\n",
       "         var_195  var_196  var_197  var_198  var_199  \n",
       "ID_code                                               \n",
       "test_0    2.4669   4.3654  10.7200  15.4722  -8.7197  \n",
       "test_1    0.4773  -1.4852   9.8714  19.1293 -20.9760  \n",
       "test_2    2.1281  -7.1086   7.0618  19.8956 -23.1794  \n",
       "test_3    3.1656   3.9567   9.2295  13.0168  -4.2108  \n",
       "test_4   -0.2860  -5.1612   7.2882  13.9260  -9.1846  \n",
       "\n",
       "[5 rows x 200 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(test.shape)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200000, 200)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>var_9</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID_code</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train_0</th>\n",
       "      <td>8.9255</td>\n",
       "      <td>-6.7863</td>\n",
       "      <td>11.9081</td>\n",
       "      <td>5.0930</td>\n",
       "      <td>11.4607</td>\n",
       "      <td>-9.2834</td>\n",
       "      <td>5.1187</td>\n",
       "      <td>18.6266</td>\n",
       "      <td>-4.9200</td>\n",
       "      <td>5.7470</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4354</td>\n",
       "      <td>3.9642</td>\n",
       "      <td>3.1364</td>\n",
       "      <td>1.6910</td>\n",
       "      <td>18.5227</td>\n",
       "      <td>-2.3978</td>\n",
       "      <td>7.8784</td>\n",
       "      <td>8.5635</td>\n",
       "      <td>12.7803</td>\n",
       "      <td>-1.0914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_1</th>\n",
       "      <td>11.5006</td>\n",
       "      <td>-4.1473</td>\n",
       "      <td>13.8588</td>\n",
       "      <td>5.3890</td>\n",
       "      <td>12.3622</td>\n",
       "      <td>7.0433</td>\n",
       "      <td>5.6208</td>\n",
       "      <td>16.5338</td>\n",
       "      <td>3.1468</td>\n",
       "      <td>8.0851</td>\n",
       "      <td>...</td>\n",
       "      <td>7.6421</td>\n",
       "      <td>7.7214</td>\n",
       "      <td>2.5837</td>\n",
       "      <td>10.9516</td>\n",
       "      <td>15.4305</td>\n",
       "      <td>2.0339</td>\n",
       "      <td>8.1267</td>\n",
       "      <td>8.7889</td>\n",
       "      <td>18.3560</td>\n",
       "      <td>1.9518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_2</th>\n",
       "      <td>8.6093</td>\n",
       "      <td>-2.7457</td>\n",
       "      <td>12.0805</td>\n",
       "      <td>7.8928</td>\n",
       "      <td>10.5825</td>\n",
       "      <td>-9.0837</td>\n",
       "      <td>6.9427</td>\n",
       "      <td>14.6155</td>\n",
       "      <td>-4.9193</td>\n",
       "      <td>5.9525</td>\n",
       "      <td>...</td>\n",
       "      <td>2.9057</td>\n",
       "      <td>9.7905</td>\n",
       "      <td>1.6704</td>\n",
       "      <td>1.6858</td>\n",
       "      <td>21.6042</td>\n",
       "      <td>3.1417</td>\n",
       "      <td>-6.5213</td>\n",
       "      <td>8.2675</td>\n",
       "      <td>14.7222</td>\n",
       "      <td>0.3965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_3</th>\n",
       "      <td>11.0604</td>\n",
       "      <td>-2.1518</td>\n",
       "      <td>8.9522</td>\n",
       "      <td>7.1957</td>\n",
       "      <td>12.5846</td>\n",
       "      <td>-1.8361</td>\n",
       "      <td>5.8428</td>\n",
       "      <td>14.9250</td>\n",
       "      <td>-5.8609</td>\n",
       "      <td>8.2450</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4666</td>\n",
       "      <td>4.7433</td>\n",
       "      <td>0.7178</td>\n",
       "      <td>1.4214</td>\n",
       "      <td>23.0347</td>\n",
       "      <td>-1.2706</td>\n",
       "      <td>-2.9275</td>\n",
       "      <td>10.2922</td>\n",
       "      <td>17.9697</td>\n",
       "      <td>-8.9996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_4</th>\n",
       "      <td>9.8369</td>\n",
       "      <td>-1.4834</td>\n",
       "      <td>12.8746</td>\n",
       "      <td>6.6375</td>\n",
       "      <td>12.2772</td>\n",
       "      <td>2.4486</td>\n",
       "      <td>5.9405</td>\n",
       "      <td>19.2514</td>\n",
       "      <td>6.2654</td>\n",
       "      <td>7.6784</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.4905</td>\n",
       "      <td>9.5214</td>\n",
       "      <td>-0.1508</td>\n",
       "      <td>9.1942</td>\n",
       "      <td>13.2876</td>\n",
       "      <td>-1.5121</td>\n",
       "      <td>3.9267</td>\n",
       "      <td>9.5031</td>\n",
       "      <td>17.9974</td>\n",
       "      <td>-8.8104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           var_0   var_1    var_2   var_3    var_4   var_5   var_6    var_7  \\\n",
       "ID_code                                                                       \n",
       "train_0   8.9255 -6.7863  11.9081  5.0930  11.4607 -9.2834  5.1187  18.6266   \n",
       "train_1  11.5006 -4.1473  13.8588  5.3890  12.3622  7.0433  5.6208  16.5338   \n",
       "train_2   8.6093 -2.7457  12.0805  7.8928  10.5825 -9.0837  6.9427  14.6155   \n",
       "train_3  11.0604 -2.1518   8.9522  7.1957  12.5846 -1.8361  5.8428  14.9250   \n",
       "train_4   9.8369 -1.4834  12.8746  6.6375  12.2772  2.4486  5.9405  19.2514   \n",
       "\n",
       "          var_8   var_9   ...     var_190  var_191  var_192  var_193  var_194  \\\n",
       "ID_code                   ...                                                   \n",
       "train_0 -4.9200  5.7470   ...      4.4354   3.9642   3.1364   1.6910  18.5227   \n",
       "train_1  3.1468  8.0851   ...      7.6421   7.7214   2.5837  10.9516  15.4305   \n",
       "train_2 -4.9193  5.9525   ...      2.9057   9.7905   1.6704   1.6858  21.6042   \n",
       "train_3 -5.8609  8.2450   ...      4.4666   4.7433   0.7178   1.4214  23.0347   \n",
       "train_4  6.2654  7.6784   ...     -1.4905   9.5214  -0.1508   9.1942  13.2876   \n",
       "\n",
       "         var_195  var_196  var_197  var_198  var_199  \n",
       "ID_code                                               \n",
       "train_0  -2.3978   7.8784   8.5635  12.7803  -1.0914  \n",
       "train_1   2.0339   8.1267   8.7889  18.3560   1.9518  \n",
       "train_2   3.1417  -6.5213   8.2675  14.7222   0.3965  \n",
       "train_3  -1.2706  -2.9275  10.2922  17.9697  -8.9996  \n",
       "train_4  -1.5121   3.9267   9.5031  17.9974  -8.8104  \n",
       "\n",
       "[5 rows x 200 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = train.loc[:,train.columns !='target']\n",
    "print(x.shape)\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200000,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ID_code\n",
       "train_0    0\n",
       "train_1    0\n",
       "train_2    0\n",
       "train_3    0\n",
       "train_4    0\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = train['target']\n",
    "print(y.shape)\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = scaler.transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-1.1152668122349497e-15, 1.0000000000000013)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.mean(), x.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.reshape(y.shape[0],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200000, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       ...,\n",
       "       [0],\n",
       "       [0],\n",
       "       [0]], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(y.shape)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_valid, y_train, y_valid = train_test_split(x,y,test_size=0.3, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((140000, 200), (60000, 200), (140000, 1), (60000, 1))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_valid.shape,y_train.shape, y_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=torch.FloatTensor(x_train)\n",
    "x_valid=torch.FloatTensor(x_valid)\n",
    "y_train=torch.FloatTensor(y_train)\n",
    "y_valid=torch.FloatTensor(y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([140000, 200]),\n",
       " torch.Size([60000, 200]),\n",
       " torch.Size([140000, 1]),\n",
       " torch.Size([60000, 1]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.size(), x_valid.size(),y_train.size(), y_valid.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data_utils.TensorDataset(x_train, y_train)\n",
    "valid = data_utils.TensorDataset(x_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(train, batch_size=20000, shuffle=True)\n",
    "validloader = torch.utils.data.DataLoader(valid, batch_size=20000, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, label =next(iter(trainloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([20000, 200]), torch.Size([20000, 1]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.size(), label.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid, label =next(iter(validloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([20000, 200]), torch.Size([20000, 1]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid.size(), label.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=200, out_features=150, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Dropout(p=0.2)\n",
       "  (3): Linear(in_features=150, out_features=100, bias=True)\n",
       "  (4): ReLU()\n",
       "  (5): Dropout(p=0.2)\n",
       "  (6): Linear(in_features=100, out_features=50, bias=True)\n",
       "  (7): ReLU()\n",
       "  (8): Dropout(p=0.2)\n",
       "  (9): Linear(in_features=50, out_features=1, bias=True)\n",
       "  (10): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc1 = nn.Linear(200, 150)\n",
    "ac1 = nn.ReLU()\n",
    "dr1 = nn.Dropout(p=0.2)\n",
    "fc2 = nn.Linear(150, 100)\n",
    "ac2 = nn.ReLU()\n",
    "dr2 = nn.Dropout(p=0.2)\n",
    "fc3 = nn.Linear(100, 50)\n",
    "ac3 = nn.ReLU()\n",
    "dr3 = nn.Dropout(p=0.2)\n",
    "fc4 = nn.Linear(50, 1)\n",
    "ac4 = nn.Sigmoid()\n",
    "        \n",
    "model = nn.Sequential(fc1,ac1,dr1,fc2,ac2,dr2,fc3,ac3,dr3,fc4,ac4)\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0/200 training_loss:  4.330 validation_loss:  1.151\n",
      "epoch: 10/200 training_loss:  1.670 validation_loss:  0.752\n",
      "epoch: 20/200 training_loss:  1.600 validation_loss:  0.752\n",
      "epoch: 30/200 training_loss:  1.508 validation_loss:  0.768\n",
      "epoch: 40/200 training_loss:  1.394 validation_loss:  0.798\n",
      "epoch: 50/200 training_loss:  1.321 validation_loss:  0.831\n",
      "epoch: 60/200 training_loss:  1.249 validation_loss:  0.877\n",
      "epoch: 70/200 training_loss:  1.195 validation_loss:  0.911\n",
      "epoch: 80/200 training_loss:  1.133 validation_loss:  0.948\n",
      "epoch: 90/200 training_loss:  1.099 validation_loss:  0.974\n",
      "epoch: 100/200 training_loss:  1.055 validation_loss:  1.015\n",
      "epoch: 110/200 training_loss:  1.017 validation_loss:  1.053\n",
      "epoch: 120/200 training_loss:  0.996 validation_loss:  1.064\n",
      "epoch: 130/200 training_loss:  0.964 validation_loss:  1.096\n",
      "epoch: 140/200 training_loss:  0.934 validation_loss:  1.118\n",
      "epoch: 150/200 training_loss:  0.905 validation_loss:  1.138\n",
      "epoch: 160/200 training_loss:  0.885 validation_loss:  1.151\n",
      "epoch: 170/200 training_loss:  0.863 validation_loss:  1.172\n",
      "epoch: 180/200 training_loss:  0.843 validation_loss:  1.209\n",
      "epoch: 190/200 training_loss:  0.829 validation_loss:  1.215\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.003)\n",
    "\n",
    "epochs = 200\n",
    "\n",
    "training_loss =[]\n",
    "validation_loss =[]\n",
    "\n",
    "for e in range(epochs):\n",
    "   \n",
    "    running_losses = 0\n",
    "    for trains, labels in trainloader:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(trains)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_losses += loss.item()\n",
    "        \n",
    "    else:\n",
    "        test_losses = 0 \n",
    "        \n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            for valids, labels in validloader:\n",
    "                \n",
    "                ps = model(valids)\n",
    "                test_losses += criterion(ps, labels)\n",
    "        \n",
    "        training_loss.append(running_losses)\n",
    "        validation_loss.append(test_losses)\n",
    "    \n",
    "    \n",
    "        if validation_loss[e-1] > validation_loss[e]:\n",
    "            torch.save(model, '../model/nn_model' + '{e}' +'pth')\n",
    "        \n",
    "\n",
    "        model.train()\n",
    "        \n",
    "        if e % 10 == 0:\n",
    "            print(f\"epoch: {e}/{epochs}\", \n",
    "                 f\"training_loss: {training_loss[e]: .3f}\",\n",
    "                 f\"validation_loss: {validation_loss[e]: .3f}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x229adafa4a8>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAIABJREFUeJzt3Xl8lOW9///XZ2ayb5ONEJKQgCyyJxARi4K4HcCtVk+l1VPtqaW19bS2x1Ztz3HrOb+v7ddav9aqR6vWtlrxuFL3oihuoOz7ToAQIPu+Z67fH9cQkjAzCSHJZMLn+XjMI5N7rpn5cCe8c811X/d1izEGpZRSQ4sj2AUopZTqexruSik1BGm4K6XUEKThrpRSQ5CGu1JKDUEa7kopNQT1ONxFxCki60TkDR+P3SgiJSKy3nu7qW/LVEopdTJcJ9H2x8A2IN7P40uMMbeceklKKaVOVY967iKSCVwK/LF/y1FKKdUXetpzfwj4ORAXoM3VIjIH2An8xBhzMNALpqSkmJycnB6+vVJKKYA1a9aUGmNSu2vXbbiLyGVAsTFmjYic76fZ34G/GWOaROT7wLPABT5eazGwGGDkyJGsXr26u7dXSinVgYjs70m7ngzLzAauEJEC4AXgAhH5a8cGxpgyY0yT99sngRm+XsgY84QxJt8Yk5+a2u0fHqWUUr3UbbgbY+40xmQaY3KARcAHxpjrO7YRkfQO316BPfCqlFIqSE5mtkwnInIfsNoYsxT4kYhcAbQC5cCNfVOeUkqp3pBgLfmbn59vdMxdqYHV0tJCYWEhjY2NwS5FdSMyMpLMzEzCwsI6bReRNcaY/O6e3+ueu1Iq9BQWFhIXF0dOTg4iEuxylB/GGMrKyigsLGTUqFG9eg1dfkCp00hjYyPJycka7IOciJCcnHxKn7A03JU6zWiwh4ZT/TmFXLjvOFLDb9/bQVltU/eNlVLqNBVy4b67uJbff7CbsrrmYJeilDpJlZWVPProo7167sKFC6msrAzY5q677mLZsmW9ev2ucnJyKC0t7ZPXCoaQC3ent+LWNr2wt1KhJlC4t7W1BXzuW2+9hdvtDtjmvvvu46KLLup1fUNJCIa7LdkTpCmcSqneu+OOO9izZw+5ubn87Gc/48MPP2TevHl885vfZMqUKQB89atfZcaMGUyaNIknnnii/bnHetIFBQVMmDCB7373u0yaNIlLLrmEhoYGAG688UZeeuml9vZ3330306dPZ8qUKWzfvh2AkpISLr74YqZPn873vvc9srOzu+2hP/jgg0yePJnJkyfz0EMPAVBXV8ell17KtGnTmDx5MkuWLGn/N06cOJGpU6dy22239e0OPAkhNxWyvefu0XBX6lTc+/ctbC2q7tPXnDginrsvn+T38fvvv5/Nmzezfv16AD788EO++OILNm/e3D7l7+mnnyYpKYmGhgbOOussrr76apKTkzu9zq5du/jb3/7Gk08+yde//nVefvllrr/++hPeLyUlhbVr1/Loo4/ywAMP8Mc//pF7772XCy64gDvvvJN33nmn0x8QX9asWcMzzzzDqlWrMMZw9tlnM3fuXPbu3cuIESN48803AaiqqqK8vJxXX32V7du3IyLdDiP1p5DtubdpuCs1JMycObPTXO6HH36YadOmMWvWLA4ePMiuXbtOeM6oUaPIzc0FYMaMGRQUFPh87a997WsntPnkk09YtGgRAPPnzycxMTFgfZ988glXXXUVMTExxMbG8rWvfY2PP/6YKVOmsGzZMm6//XY+/vhjEhISiI+PJzIykptuuolXXnmF6Ojok90dfSb0eu7e6UEa7kqdmkA97IEUExPTfv/DDz9k2bJlfP7550RHR3P++ef7nOsdERHRft/pdLYPy/hr53Q6aW1tBewJQifDX/tx48axZs0a3nrrLe68804uueQS7rrrLr744gvef/99XnjhBR555BE++OCDk3q/vhJyPXdvx13DXakQFBcXR01Njd/Hq6qqSExMJDo6mu3bt7Ny5co+r+Hcc8/lxRdfBOC9996joqIiYPs5c+bw2muvUV9fT11dHa+++irnnXceRUVFREdHc/3113Pbbbexdu1aamtrqaqqYuHChTz00EPtw0/BEHI9d5cOyygVspKTk5k9ezaTJ09mwYIFXHrppZ0enz9/Po8//jhTp05l/PjxzJo1q89ruPvuu/nGN77BkiVLmDt3Lunp6cTF+b8O0fTp07nxxhuZOXMmADfddBN5eXm8++67/OxnP8PhcBAWFsZjjz1GTU0NV155JY2NjRhj+N3vftfn9fdUyC0ctmZ/OVc/9jnP/utM5o7TNeGVOhnbtm1jwoQJwS4jqJqamnA6nbhcLj7//HNuvvnmoPawA/H18xqyC4e1T4XUnrtSqhcOHDjA17/+dTweD+Hh4Tz55JPBLqlfhF64ew+o6lRIpVRvjB07lnXr1gW7jH4XcgdUnQ6dLaOUUt3RcFdKqSEodMNdlx9QSim/QjfcPZ4gV6KUUoNXj8NdRJwisk5E3vDxWISILBGR3SKySkRy+rLIjlzt4d5f76CUGkxiY2MBKCoq4pprrvHZ5vzzz6e7qdUPPfQQ9fX17d/3ZAnhnrjnnnt44IEHTvl1+trJ9Nx/DGzz89h3gApjzBjgd8CvT7Uwfxzac1fqtDRixIj2FR97o2u492QJ4VDWo3AXkUzgUuCPfppcCTzrvf8ScKH007W8tOeuVOi6/fbbO63nfs899/Db3/6W2tpaLrzwwvbleV9//fUTnltQUMDkyZMBaGhoYNGiRUydOpVrr72209oyN998M/n5+UyaNIm7774bsIuRFRUVMW/ePObNmwd0vhiHryV9Ay0t7M/69euZNWsWU6dO5aqrrmpf2uDhhx9uXwb42KJlH330Ebm5ueTm5pKXlxdwWYbe6Ok894eAnwP+ztHNAA4CGGNaRaQKSAY6LZIsIouBxQAjR47sTb04RHvuSvWJt++AI5v69jWHT4EF9/t9eNGiRdx666384Ac/AODFF1/knXfeITIykldffZX4+HhKS0uZNWsWV1xxhd/riD722GNER0ezceNGNm7cyPTp09sf++///m+SkpJoa2vjwgsvZOPGjfzoRz/iwQcfZPny5aSkpHR6LX9L+iYmJvZ4aeFjvvWtb/H73/+euXPnctddd3Hvvffy0EMPcf/997Nv3z4iIiLah4IeeOAB/vCHPzB79mxqa2uJjIzs8W7uiW577iJyGVBsjFkTqJmPbSdMZzHGPGGMyTfG5Kem9m7pAJdOhVQqZOXl5VFcXExRUREbNmwgMTGRkSNHYozhF7/4BVOnTuWiiy7i0KFDHD161O/rrFixoj1kp06dytSpU9sfe/HFF5k+fTp5eXls2bKFrVu3BqzJ35K+0POlhcEuelZZWcncuXMBuOGGG1ixYkV7jddddx1//etfcblsn3r27Nn89Kc/5eGHH6aysrJ9e1/pyavNBq4QkYVAJBAvIn81xnT881UIZAGFIuICEoDyPq3U69iYu56hqtQpCtDD7k/XXHMNL730EkeOHGkfonjuuecoKSlhzZo1hIWFkZOT43Op34589er37dvHAw88wJdffkliYiI33nhjt68TaH2tni4t3J0333yTFStWsHTpUn71q1+xZcsW7rjjDi699FLeeustZs2axbJlyzjzzDN79fq+dNtzN8bcaYzJNMbkAIuAD7oEO8BS4Abv/Wu8bfolfY9NhdTL7CkVmhYtWsQLL7zASy+91D77paqqimHDhhEWFsby5cvZv39/wNeYM2cOzz33HACbN29m48aNAFRXVxMTE0NCQgJHjx7l7bffbn+Ov+WG/S3pe7ISEhJITExs7/X/5S9/Ye7cuXg8Hg4ePMi8efP4zW9+Q2VlJbW1tezZs4cpU6Zw++23k5+f334ZwL7S688BInIfsNoYsxR4CviLiOzG9tgX9VF9J3Bpz12pkDZp0iRqamrIyMggPT0dgOuuu47LL7+c/Px8cnNzu+3B3nzzzXz7299m6tSp5Obmti/HO23aNPLy8pg0aRKjR49m9uzZ7c9ZvHgxCxYsID09neXLl7dv97ekb6AhGH+effZZvv/971NfX8/o0aN55plnaGtr4/rrr6eqqgpjDD/5yU9wu93853/+J8uXL8fpdDJx4kQWLFhw0u8XSMgt+dvc6mHcf7zNbZeM45YLxvZDZUoNXbrkb2g5lSV/Q+4MVZ0KqZRS3Qu5cNeTmJRSqnshF+5ge++6cJhSvROsoVh1ck715xSS4e5wiB5QVaoXIiMjKSsr04Af5IwxlJWVndKJTSF3JSawPXe9zJ5SJy8zM5PCwkJKSkqCXYrqRmRkJJmZmb1+fkiGu1O0565Ub4SFhTFq1Khgl6EGQEgOyzid2nNXSqlAQjPcteeulFIBhWa4O0SXH1BKqQBCNtxb2zTclVLKn5AMd4foPHellAokJMPd5RRdz10ppQIIyXB3ioa7UkoFEprh7tBwV0qpQDTclVJqCArZcNepkEop5V/IhruexKSUUv6FbLjrsIxSSvnXbbiLSKSIfCEiG0Rki4jc66PNjSJSIiLrvbeb+qdcS2fLKKVUYD1ZFbIJuMAYUysiYcAnIvK2MWZll3ZLjDG39H2JJ9Keu1JKBdZtz91Ytd5vw7y3oCarhrtSSgXWozF3EXGKyHqgGPiHMWaVj2ZXi8hGEXlJRLL6tMounHqZPaWUCqhH4W6MaTPG5AKZwEwRmdylyd+BHGPMVGAZ8Kyv1xGRxSKyWkRWn8qVYLTnrpRSgZ3UbBljTCXwITC/y/YyY0yT99sngRl+nv+EMSbfGJOfmprai3Itl4a7UkoF1JPZMqki4vbejwIuArZ3aZPe4dsrgG19WWRXDp0to5RSAfVktkw68KyIOLF/DF40xrwhIvcBq40xS4EficgVQCtQDtzYXwWDDssopVR3ug13Y8xGIM/H9rs63L8TuLNvS/NPw10ppQIL3TNUdbaMUkr5FbLhrpfZU0op/0Iz3EVXhVRKqUBCMtz1MntKKRVYSIa7ToVUSqnAQjLcXXpAVSmlAgrJcHc4hDY9oKqUUn6FZLhrz10ppQILyXB36GX2lFIqoJAMd5dD8Gi4K6WUXyEZ7k7RnrtSSgUSkuHucAiA9t6VUsqPkAx3lzfctfeulFK+hWS4t/fcdcaMUkr5FJLhrj13pZQKLCTD3SE23HUJAqWU8i0kw92lB1SVUiqgkAx3pw7LKKVUQCEa7rZsPaCqlFK+dRvuIhIpIl+IyAYR2SIi9/poEyEiS0Rkt4isEpGc/ij2GKe3au25K6WUbz3puTcBFxhjpgG5wHwRmdWlzXeACmPMGOB3wK/7tszO2nvuGu5KKeVTt+FurFrvt2HeW9dUvRJ41nv/JeBCEe+Uln6gPXellAqsR2PuIuIUkfVAMfAPY8yqLk0ygIMAxphWoApI7stCOzrWc9epkEop5VuPwt0Y02aMyQUygZkiMrlLE1+99BOSV0QWi8hqEVldUlJy8tV6OXWeu1JKBXRSs2WMMZXAh8D8Lg8VAlkAIuICEoByH89/whiTb4zJT01N7VXBcHwqpIa7Ukr51pPZMqki4vbejwIuArZ3abYUuMF7/xrgA2P6b56ihrtSSgXm6kGbdOBZEXFi/xi8aIx5Q0TuA1YbY5YCTwF/EZHd2B77on6rmOMHVPVSe0op5Vu34W6M2Qjk+dh+V4f7jcA/921p/h0/oOoZqLdUSqmQEppnqLYfUA1yIUopNUiFZri3ry2j6a6UUr6EdLhrtiullG8hHe56QFUppXwL7XDXrrtSSvkUkuHucugBVaWUCiQkw/34ZfY03ZVSypeQDHeXU3vuSikVSEiG+7Geu06FVEop30Iy3NsvkK2zZZRSyqeQDPf2k5jaNNyVUsqXkAx3h/bclVIqoJAMd1f78gMa7kop5UtIhvuxA6p6gWyllPItJMNde+5KKRVYSIa7Q6/EpJRSAYVkuLs03JVSKqCQDHddFVIppQIL6XDXA6pKKeVbt+EuIlkislxEtonIFhH5sY8254tIlYis997u8vVafcUpekBVKaUC6fYC2UAr8O/GmLUiEgesEZF/GGO2dmn3sTHmsr4v8UQOhyCiPXellPKn2567MeawMWat934NsA3I6O/CuuMU0Z67Ukr5cVJj7iKSA+QBq3w8fI6IbBCRt0Vkkp/nLxaR1SKyuqSk5KSL7cjpED2gqpRSfvQ43EUkFngZuNUYU93l4bVAtjFmGvB74DVfr2GMecIYk2+MyU9NTe1tzYA33HXhMKWU8qlH4S4iYdhgf84Y80rXx40x1caYWu/9t4AwEUnp00q70J67Ukr515PZMgI8BWwzxjzop81wbztEZKb3dcv6stCunA7Rk5iUUsqPnsyWmQ38C7BJRNZ7t/0CGAlgjHkcuAa4WURagQZgkTH92612ioa7Ukr50224G2M+AaSbNo8Aj/RVUT2hPXellPIvJM9QBQ13pZQKRMNdKaWGoNAOd50to5RSPoV0uOsZqkop5VvohruIri2jlFJ+hG6465i7Ukr5FbLhHuZ00NzmCXYZSik1KIVsuCdEhVHV0BLsMpRSalAK2XB3R4dRWa/hrpRSvoRsuCdGh1NR3xzsMpRSalAK4XC3wzJ6UFUppU4UsuHujg7HGKjWcXellDpByIZ7YkwYgA7NKKWUD6Eb7tHhAFToQVWllDpB6Id7nfbclVKqq9APdx2WUUqpE4RsuLu9Y+46110ppU4UsuEeF+HC5RDtuSullA89uUB2logsF5FtIrJFRH7so42IyMMisltENorI9P4pt9N74o4O0wOqSinlQ08ukN0K/LsxZq2IxAFrROQfxpitHdosAMZ6b2cDj3m/9it3dDiV2nNXSqkTdNtzN8YcNsas9d6vAbYBGV2aXQn82VgrAbeIpPd5tV0k6RIESinl00mNuYtIDpAHrOryUAZwsMP3hZz4B6DP6eJhSinlW4/DXURigZeBW40x1V0f9vGUExZ9EZHFIrJaRFaXlJScXKU+6OJhSinlW4/CXUTCsMH+nDHmFR9NCoGsDt9nAkVdGxljnjDG5Btj8lNTU3tTbyfuGHtA1eiFspVSqpOezJYR4ClgmzHmQT/NlgLf8s6amQVUGWMO92GdPiVGh9Pc6qGhpa2/30oppUJKT2bLzAb+BdgkIuu9234BjAQwxjwOvAUsBHYD9cC3+77UEyVGH1s8rIXo8J78U5RS6vTQbSIaYz7B95h6xzYG+GFfFdVTbu8SBOW1zWS4owb67ZVSatAK2TNUAUalxACw/UjX47tKKXV6C+lwH5Maizs6jC8LyoNdilJKDSohHe4Oh5CfncSXBRXBLkUppQaVkA53gJmjEtlXWkdxTWOwS1FKqUEj5MP9rJwkAFZr710ppdqFfLhPzkggMszBF/t03F0ppY4J+XAPczo4Z3Qy/7v6IGsPaO9dKaVgCIQ7wP1XTyUlLoIbnv6Cz/eUBbscpZQKuiER7mnxkTx309kMi4vg+qdW8cSKPbrejFLqtDYkwh0gMzGa1285l0smpvH/vbWdHz6/lppGXQ5YKXV6GjLhDhAb4eLR66bzi4Vn8u6Wo1z68Ces2a/j8Eqp08+QCnew11ZdPOcMliyeRZvHcM3jn3HnK5tYf7CSljZPsMtTSqkBIcEam87PzzerV6/u1/eoaWzhoWW7+NNnBbR5DDHhTs4dm8K88cOYd+Yw0uIj+/X9lVKqr4nIGmNMfrfthnK4H1Nc3ciXBRV8uqeU5duLOVxlz2adNCKe/OxEpmW5mT95uC4brJQa9DTc/TDGsONoDR9sL+bDHSVsOVRFXXMbcZEu5o5LJTfLTd5IN5NGJBAZ5hzw+pRSKhAN9x7yeAxrDlTwt1UHWLm3jCJvr97lECaOiOfCM9OYMy6FCenxGvZKqaDTcO+l4upG1h+sZENhJav2lrPmQAXG2LAflxbH9Gw3s89I4ZwzktsvFqKUUgNFw72PlNQ0sWZ/BZsOVbKxsIq1+yuoa25DBPKzE7l+VjaXTBxOVLj26pVS/U/DvZ+0tHnYcLCST3aX8tq6QxSU1RMZ5uDcMalcMjGNf5o8nISosGCXqZQaovos3EXkaeAyoNgYM9nH4+cDrwP7vJteMcbc190bh2q4d+TxGFbuLeO9rUd5b8sRiqoaiQxzcMW0EfzbBWPJSooOdolKqSGmL8N9DlAL/DlAuN9mjLnsZAocCuHekTGGjYVVLFl9kJfXFGIMzBmXytzxqcwdm8rIZA16pdSp62m4dzux2xizQkRy+qKooUxEmJblZlqWm3+7YAz/89Felm07yrJtRwF7Me+LJ6bxbxeMIS5Sh22UUv2rR2Pu3nB/I0DP/WWgECjC9uK3dPeaQ63n7osxhr2ldazYWcKKnSV8tLOEjMQo/uurU5gzNgURCXaJSqkQ06cHVLsJ93jAY4ypFZGFwP8zxoz18zqLgcUAI0eOnLF///5u33soWbO/nJ8s2cCB8nqmZCRw6dR0Lp82ggx3VLBLU0qFiAELdx9tC4B8Y0xpoHanQ8/dl6bWNl5aU8hzKw+w9XA1Lofw1bwMfnLxOA15pVS3+mzMvQdvNBw4aowxIjITu9KkXg7JjwiXk+vOzua6s7M5WF7P05/u4/lVB/j7hiIunZLOxBHxnD9+GGOGxQa7VKVUCOvJbJm/AecDKcBR4G4gDMAY87iI3ALcDLQCDcBPjTGfdffGp2vP3ZdDlQ389r0dfLq7lKPVTQBMy3Jzy7wxjB0Wy/CESF36QCkF6ElMIetwVQNvbzrC05/uo7CiAYDE6DB+cP4Y5oxLJTs5WoNeqdOYhnuIa2718OnuUsrqmnl9/SE+3mUPYcRGuLh8Wjo3fmUU44fHBblKpdRA03AfYrYdrmbn0RpW7CzlzU1FNLZ4OHtUEuOHxzE5I4GzRyWRnRwT7DKVUv1Mw30Iq6hr5tnPC3h/WzH7SuuobWoFYOywWK6ansG1+Vkkx0YEt0ilVL/QcD9NeDyGPSW1fLK7lLc3H+GLfeWEOYW541K5fNoIZo9Jobi6iZS4cIbF6WUFlQp1AzYVUgWXwyGMTYtjbFoc3549il1Ha/jfNYX8fUMRy7YVd2qbm+Xmxq/kcNnUdFzOIXdtdKVUB9pzH6KOXWFq/YFK0t2R7C+r57V1h9hVXEtmYhTXz8om3OkgOTacOWNTSYzRC48oFQp0WEadwOMxfLC9mEc/3M3aA5Xt20UgKzGa88encvv8M4mJ0A90Sg1WOiyjTuBwCBdNTOPCCcM4XNVIVJiT/eX1rNhZwtaiav6ycj8rdpZwVk4SEWEOosKcjEyKZlJGAtMy3TgdutCZUiel8gDsfBccThhzMbizBuytNdxPQyLCCO86Nokx4eRmuQFYubeM/35zG5/uLqWx1UN9cyuNLR4AkmLCmZmTxFmjkvinSWlkJur69Oo00tIIRzbCiDxw9nDJ7qL18Nerod67zJYzAvL/FaZdC+m59iNzP9JhGeWXMYYj1Y18WVDBh9uLWb2/ggPl9QDkJEczOSOBKd7bpIwEvbygCh2NVXDwC0gabW+BgvbASlj6IyjdYdtOvwGSRkFzPUQmQNbZEJN8vH1DBax8HD77PUQnwaLnISwKPn4QNi4B0wZn3wwL7u9V6TrmrvpFQWkd72w5wroDFWw+VM2hyob2x0YmRTMlI4GJI+LJTo4mLjKMCJeDGdmJhOnsHNXfaouhaB1kz4aIDgvvGQN1JRAWDeEx0NoIT11ie+IAZ14Gs2+FTx6034+YDmfMg6ObYfUzcHg9xI2Ar/wbrH8ejm7q8sYCedfByK/A1tdhzwfgaYEJV8D8+yEh43jT+nLY8RakjIess3r1z9RwVwOirLaJzUXVbD5UxeZDVWw6VNW+Js4x6QmRLJiczqjUGPKy3IwZFouIXSFTnYbK94I7245Dd2QM7HwHyvbAhMshMdturyuFwi+hqcYGZljk8fbGAyXb4f1fwa537fdRiXDWd2HilfDJ72DH29BSZ58TnwnukXDgM7jsd1BbAh/d731eEsSkQulOwJuLwybCjG/DtEUQGW+3NVTYsfTwWPsHZevr8OUfbaAnZMGkr8LUa2H4lH7ZfRruKmhqGlsorGigvrmN4upG/rpqP6sLKmhq9XRql5vlZnxaHEVVDUzOSODyqSOYOCI+SFWrPle6G1b+wYbg7FvtEMWye+DTh2xPOOdccIbDlKttm7dug8Mbjj9/whWQNtn2qFsb7ba4dBvCJdvt8MYxkQk20DPPgnV/ge1v2O3OCMj9JgybAC0NUPAx7H4f5v4c5v3Cttm3wm77yo/s8EpdKez90AZ11syejY1XHrSfDtJzwdG/n1KHbrhvfwveuBW+8x4k5vR5Xap/GGM4VNnA6oIKiqoaaGxu44MdxRypamRYXCQ7jtbQ5jHMHJXEjOxERiZFs3ByOvFRLjwGnakTLMZA6S5oa7bhdWAljLnQhl5H9eXQXAvNdXZoZPMrsOd9G95tzTZko5Og+hBM+WdorIaSbfZro3dabnwGzPslZJ8D656DlY/ZHveZl8E5t9iA//wRW9PwKXYcWxwQEWd7ytFJx+sp2WmHPyZcDslndK61sfp4LzwEDd1w3/sh/PlKuOHvMGpOn9elgqOirpmX1hTy/BcHOFheT6vHEO5y4HIIbR7DRRPTGJUcQ1S4k6unZ5IWH0Fji4eocB3a6RVjYPub8PkfoGKfPVB4ya8gY4Z9vLEa1vwJ1j4LZbu7PFlg/AI7TNJcC/Vldpiio7gRtsd89vfs46ufsV+zzoaZ3z3eG25tgnV/tQE/83udx8prS6CmCNKn9ddeCElDN9zL98HDuXDFIzD9X/q+MBV0xhi2Hq7m9fVFtHkMjS1tvL35CJX1zXgMhDsdRIY5qGlqZd74YUwf6aalzZCVFE16QiRR4U6yk6JJignXi5B3VF9uZ2tsfxOqCm2oJ4+xQxm734e6YjvkERELNUehrckeJJz6zxCdbA9Ipk+DFQ/Ycez4dIiItz3n9Kl2vNoZbodSUsefOKau+sTQDfe2FvivYXDev8MF/9H3halByRiDiHCwvJ4/fVZAQ0sbsREuXll7iNLaJp/PyUqK4vKpI6htaqXIZUMWAAASkUlEQVTNYzh3TApj0+LITIwKjQue1JXaoYiETP9tyvfCZ4/A1tfsEEXKeMj9hg3wA5/bg4FjL7Zj2cv/DzRV2SGNpNH2k+/0G8Hpsj319c/boZKWBogdBpOuOt6TV4PG0A13gN9NgZGz4Oon+7YoFXI8HkOrx+AQ2F9eT2lNE7VNrewrrWP5jmI+3V1GTLgTEWlfGjnMKUzLdHPOGcnMGp3MjOxESmqaOFLdSF6WOziLqhkDNYdtQEenQO0RO12v+hDknAd514PDZXvelQftmHHOebDqcfC0wviFtgdd8LEN/LAYyP4K7F5G+8yP0fPg4vtsL1uFrKEd7n+6zB6k+c57fVuUGnJqm1qJDnPSZgwbC6s4UF7H9iM1rNxbzqbCSjwGHAKeYzPf4iKYPjKRdHckk0ckUFTZwO6SWr573mgmZyR0/4ZNtbYXnTIeMvOPjy23NNqhEHcWuCJgz3I7lu2KsNMCV/0P7HjTto1OBlcUNFXDWd+BLa9CRYF9zJ1te97le6F4qx3Dvvqp46e1ezxwcKXtmccNt9MKqw7a2SgZM/r9rEjV//os3EXkaeAyoNgYM9nH4wL8P2AhUA/caIxZ290bn1K4v/ZD2yO5bUfvnq8Udsrm6oIKviwoJy0+kqSYcN7YWMTekjoOVdqpnAAx4U6aWj2MTI7mUEUDs0Ynk5vlJjrcyfSwArJqNtDiiCDdcxjXpheh9qh9g9g0O6RSV2J72xgbziNy7dzojlyRMPvHdtz6wOdw8Ev46qMw6jzbqz+w0o6B58yxU+2MsaEdN8IOq6jTRl8uHPYn4BHgz34eXwCM9d7OBh7zfu0/idn2Y2tLg50OpdTJqi0hzhXBvLGJzEssBXcKRMRy+bQRUHMET8GnHK1qIDwzF+ewcTz8zkZaygoYMbyNlwuFVTsLuc65jFzXC4SJ/SPQjIsdUVNYN/EuXNUHyapex7CaCpLTphOfe50N+1X/A9v+DnN+DmfdBK0Ndtpe6vjjJ+3M/G7nWkXs9MCu29wjB2BHqVDVbbgbY1aISE6AJlcCfzb2I8BKEXGLSLox5nAf1Xgit/c/QeVBSB3Xb2+jhojyvXBkkx2Tbqq1Bxs3LgEMOMLsmYWRCTBuPlTsh8IvcBgP6ceenzKOu8r32XbAzc4ITAxIWxMVWRezfsovMcbwdoFh1f5qCtfV445OIzZiFoerGpAy4YrwEZTua6LK82vc7gqSy0bhefswdU2t5I08gwsTkhjjnSUUHe5iVIpeD1edmr74PJcBHOzwfaF32wnhLiKLgcUAI0eeQq/jWA+ncr+G++nG47HDEp42KFxtx6xTxkF4tB2q8LTZKXhN1XBoDWx6CTa80PlsRlcknPNDe9JLY5UdH9/5jp0OmDTazsQ681J74s2ud+0ZjOMX2rFuZzgcXIUAjLmQxFHnM897RuIF3s+rbR7TftJVaW0T9yzdwlubDpOTHENqXBQtnkg+2llCmEMIdzl4d8tR7n97O0kx4ZTXNQMwIzuRhKgwEqPDmZqZwJTMBCamx4fGLB81KPRFuPs6QuNzIN8Y8wTwBNgx916/o7tDuKvTQ8lOeP9eG7SXPgjb/3583DrSDRMug70f2XFocdi1QsAemJy52C6z2tJgF45yZ0OUu/Pr513n+33TJsK5P+m8beIVAUvteDZtSmwEj3xzesD2xdWNvLHxMOsOVjL7jGTK6pp5b8sRimsa2VhYxctrCwE7v39yRjwJUWFU1Lewu7iW5NhwxqXFMXZYLGFOBxFhDvKzkxiZFE1NYwvLdxST4Y7mkklpunjbaaYvwr0Q6LgCfSZQ1Aev619smu1VVWi4h5yGStuzjog78bGi9fDFE3YdkJHn2B63M9z2rjc8b6f3uUfCKzfZ9vN+aceqN75o246aC3n/YmdSRbltjz7nPNurH8SGxUfyr+eO6rTth/PGAHZ+/+GqRjYWVrLuQCXrD1ZSWttMTISTq/IyKKtrYufRWpZvL6bV47+/FBfpIjU2gunZiVwzI5MjVY04HULeSLeuzT9E9UW4LwVuEZEXsAdSq/p1vB3sx3J31vHpYWpwqyqErUvtWh/7P7O957k/t2uQlO6ExFG2x120zva0W72rSrq8B8s9rfbU9Dm32T8KH94PKWPt6e1gV/8zZkhO8zt2YZUR7ijmT073267NYxCg2jsD6Ei1De8541LZcaSa97cVU17XzJsbD/PSmsJOzz1zeBzpCZEUlNUjQGZSNJdOGc6M7CQy3FE4HCAILofg0DV+QkZPpkL+DTgfSAGOAncDYQDGmMe9UyEfAeZjp0J+2xjT7RzHU14V8vlr7QHVH3zW+9dQfaOlEQ6ugoZy+6kqZphdma/ygO11711uh0lSJ9g1SQq/tCfbRMTbueAVBXbKYM4cOHsxlOyA4m12+CMi3p6lGa4HGPtCZX0zK/eWkZMSQ2ubYdW+ct7dcoTqhhbOSLVLMdvzAepPeG58pIuLJqRRVtdMaW0T545Noaq+haKqRmafkcxFE9M4IzUWj8fQ4vHQ5jFUNbSQFBOuyzv3oaF9EhPAe/8Bq56AXx7WNSwG0uEN8MF/2UB2uOywSMGndl2SjsRpV+0Uh12ZL+/646vzeTz2YGfq+JBenW+oMsaw/UgN2w5Xc6S60S6bbgx7S+p4f3sxafERJEaHs3p/BTHhTobFR7K7uBaA5JhwqhpaOg0RDY+P5KeXjCPc6cDpELKTo9ldXEtkmJOLJ6bR0NLG1qJqiiob+MoZKQxPiAzWPz0kDP0LZKeMtyd1VO63MxxU3zAGitbaFf8yz4Ivn/KeIbnP9r4bq+0ZlDnn2h514Wp7OvtZN9nx8MoDNvgnXO5/TRSHo9dXoVH9T0SYkB7PhPTAf3jrm1uJcDlxOoRDlQ28v+0omwqrSI2LICbChUOEmAgnS748yM9f2ujzNRKjw6hqaGk/QzjC5eCiCTbwy+qacQicOyaFDHcUUeFOxg+PI8LlpLXNw+jUWF0KOoAQDnfvFMjSXRruPdVxXLqq0I5/1x6120u229Phy/faMyrB9r5NG2TOtItIOVw22M/+/omzTY5JmzQw/xYVdNHhx+Mjwx3Ft87J8dnuurOzWXegAnd0GE2tHvaX1TM6NYaiygZeW1dEdnI0+TlJJEWH88yn+1i1r5zEGDsNtL65jT8s342vY8VxES6iwp3UNrUyOjWGienxjBkWS6vHUN/URl1zK/VNbYhAalwE+Tl2FlFhRT15IxOJjQjd+OuJ0B2WqS+H34yCS/7LXttQHddcb+dyF63zXv8x3fa+t75uD0Q219meeEcxqZB6pr36zOi59sDl3o/sioJjLw7Ov0Mp7DIRtU2tVDW0sONIDR5j8Hhg7YEKWto8RIe72FNSy5ai6vbzBBwCMeEuYiJctHoMFfXNtHX4C5EWH8H8ScP5sqCCrKQoxqfFsfVwDfFRLjvkVFDOCHcUX5ueyfnjUwlzOjhS1ch7W4+QGhvB/MnDORadDoewv6wOYyBnAE4+G/pj7gC/OcMeoLvykb4pKtQcW1+keLsdnmqssgF+ZCP29IMOP1tXlL2cWfVhG/w559pbYo7tnUe6h+RsE3X6MMZQ3dBKuMuu999xLf/GljY+31NGSU0T7ugwHv5gF9sP1zAjO5H9ZfUcrWlkdEoMNY2tVNQ3k5vlZl9pHaW1zSTFhBMb4ep0kHlcWiyHqxq99+NYe6ACAb49exSNLW0U1zQxZlgs1+ZnkZMSQ0FpHTERLlLjIk7533l6hPszC+0Zid95t2+KGmzaWu2ZljVHoHyPXeGv5rCdK162y84qaa7t/Jy0yXa8u63FXogh+xz7/KTRdo1upRTGGJrbPES4nBhjOl3V69gZxi1tHlbsLOG19UV4PIbJGQlcPDGNNfvLeeHLg4xPi8MY2HSoiosmDONwVSP/u6aQmHAn6e4o9pfVISJMTI9n/UF7KcG0+Agmj0jgqukZXDZ1RK9qH/oHVMEOMWxdakPQeMAVHuyKTk5tiZ0+2NJgpwdWHrCXIqvYbw9KVh/ihJN9I+LtOiiJOXaed+qZ9grtSaPsdEFfJwfptWaV6kRE2qdnikinyzUeO0gb5nRw4YQ0LpyQ1um5Y4bFcu1ZvpdPufXicaTE2qmfR6sb+dUbW9l+pIY7FpyJyyFsKapmS1EVhyoa+ulfdlyIh/s4G44PnmnPSpzydXstxog4O3tj2EQ71NDaZBeI6uerkrerK7VDIy2N0FJvLw1Yvtcb2IX2cmWOMDi6qfPznBH2gGVitl3q1T0SohLtxRuSz7C3yB6sKa6UCooM9/FVatPiI7tdeqI/hXa4j8izX49dmGD1U/bgYX05rH7azu5wuOyUPXHYYIxMsGPVrU12KqUz3Iaqp8UOZXhabVuHy86fd7jsH46WBvtHwxVp23javF873NpabFtfS+vEjbA96KxZNvCbauxlAhNH2fcZkWfXPNFxb6VUHwjtcM/+Cvx4w/FQbGu1Fy6oL4fNL0N1kXc5V7cN+IYKe9BRHHY1QWf48UB2hnl79y57gLFjgDvDbW+7qdr7KcDVOfyP3Zxh9hbptisIRsbbPwbu7EG/volSamgJ7XCHzuPJx65IE5104gUPlFLqNKJrgCql1BCk4a6UUkOQhrtSSg1BGu5KKTUEabgrpdQQpOGulFJDkIa7UkoNQRruSik1BAVtVUgRKQH29/LpKUBpH5bTlwZrbVrXyRmsdcHgrU3rOjm9rSvbGJPaXaOghfupEJHVPVnyMhgGa21a18kZrHXB4K1N6zo5/V2XDssopdQQpOGulFJDUKiG+xPBLiCAwVqb1nVyBmtdMHhr07pOTr/WFZJj7koppQIL1Z67UkqpAEIu3EVkvojsEJHdInJHEOvIEpHlIrJNRLaIyI+92+8RkUMist57WxiE2gpEZJP3/Vd7tyWJyD9EZJf3a2IQ6hrfYb+sF5FqEbk1GPtMRJ4WkWIR2dxhm899JNbD3t+5jSLSb9dO81PX/xWR7d73flVE3N7tOSLS0GG/PT7Adfn9uYnInd79tUNE/qm/6gpQ25IOdRWIyHrv9oHcZ/4yYmB+z4wxIXMDnMAeYDQQDmwAJgaplnRguvd+HLATmAjcA9wW5P1UAKR02fYb4A7v/TuAXw+Cn+URIDsY+wyYA0wHNne3j4CFwNuAALOAVQNc1yWAy3v/1x3qyunYLgj7y+fPzfv/YAMQAYzy/p91DmRtXR7/LXBXEPaZv4wYkN+zUOu5zwR2G2P2GmOagReAK4NRiDHmsDFmrfd+DbANyAhGLT10JfCs9/6zwFeDWAvAhcAeY0xvT2Q7JcaYFUB5l83+9tGVwJ+NtRJwi0j6QNVljHnPGNPq/XYlkNkf732ydQVwJfCCMabJGLMP2I39vzvgtYmIAF8H/tZf7+9PgIwYkN+zUAv3DOBgh+8LGQSBKiI5QB6wyrvpFu/HqqeDMfyBvUL3eyKyRkQWe7elGWMOg/2lA4YFoa6OFtH5P1yw9xn430eD6ffuX7G9u2NGicg6EflIRM4LQj2+fm6DaX+dBxw1xuzqsG3A91mXjBiQ37NQC3fxsS2o031EJBZ4GbjVGFMNPAacAeQCh7EfCQfabGPMdGAB8EMRmROEGvwSkXDgCuB/vZsGwz4LZFD83onIL4FW4DnvpsPASGNMHvBT4HkRiR/Akvz93AbF/vL6Bp07EQO+z3xkhN+mPrb1er+FWrgXAlkdvs8EioJUCyIShv2hPWeMeQXAGHPUGNNmjPEAT9KPH0f9McYUeb8WA696azh67COe92vxQNfVwQJgrTHmKAyOfeblbx8F/fdORG4ALgOuM94BWu+wR5n3/hrs2Pa4gaopwM8t6PsLQERcwNeAJce2DfQ+85URDNDvWaiF+5fAWBEZ5e39LQKWBqMQ71jeU8A2Y8yDHbZ3HCO7Ctjc9bn9XFeMiMQdu489GLcZu59u8Da7AXh9IOvqolNvKtj7rAN/+2gp8C3vbIZZQNWxj9UDQUTmA7cDVxhj6jtsTxURp/f+aGAssHcA6/L3c1sKLBKRCBEZ5a3ri4Gqq4OLgO3GmMJjGwZyn/nLCAbq92wgjhr35Q17RHkn9i/uL4NYx7nYj0wbgfXe20LgL8Am7/alQPoA1zUaO1NhA7Dl2D4CkoH3gV3er0lB2m/RQBmQ0GHbgO8z7B+Xw0ALtsf0HX/7CPtx+Q/e37lNQP4A17UbOxZ77PfscW/bq70/4w3AWuDyAa7L788N+KV3f+0AFgz0z9K7/U/A97u0Hch95i8jBuT3TM9QVUqpISjUhmWUUkr1gIa7UkoNQRruSik1BGm4K6XUEKThrpRSQ5CGu1JKDUEa7kopNQRpuCul1BD0/wMU97e44EMiRAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(training_loss, label=\"training loss\")\n",
    "plt.plot(validation_loss, label=\"validation loss\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference\n",
    "\n",
    "Now that the model is trained, we can use it for inference. We've done this before, but now we need to remember to set the model in inference mode with `model.eval()`. You'll also want to turn off autograd with the `torch.no_grad()` context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.array(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=scaler.fit_transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6.021986465043483e-16, 0.9999999999999997)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.mean(), test.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'dim'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-21e8b0f483bc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    476\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 477\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    478\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    476\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 477\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    478\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1020\u001b[0m         \u001b[1;33m-\u001b[0m \u001b[0mOutput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m:\u001b[0m\u001b[0mmath\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0m_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1021\u001b[0m     \"\"\"\n\u001b[1;32m-> 1022\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1023\u001b[0m         \u001b[1;31m# fused op is marginally faster\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1024\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'dim'"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
