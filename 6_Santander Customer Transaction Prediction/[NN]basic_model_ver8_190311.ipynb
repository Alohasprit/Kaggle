{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.utils.data as data_utils\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv('../data/train.csv', index_col='ID_code')\n",
    "test=pd.read_csv('../data/test.csv', index_col='ID_code')\n",
    "submission=pd.read_csv('../data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200000, 200)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>var_9</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID_code</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train_0</th>\n",
       "      <td>8.9255</td>\n",
       "      <td>-6.7863</td>\n",
       "      <td>11.9081</td>\n",
       "      <td>5.0930</td>\n",
       "      <td>11.4607</td>\n",
       "      <td>-9.2834</td>\n",
       "      <td>5.1187</td>\n",
       "      <td>18.6266</td>\n",
       "      <td>-4.9200</td>\n",
       "      <td>5.7470</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4354</td>\n",
       "      <td>3.9642</td>\n",
       "      <td>3.1364</td>\n",
       "      <td>1.6910</td>\n",
       "      <td>18.5227</td>\n",
       "      <td>-2.3978</td>\n",
       "      <td>7.8784</td>\n",
       "      <td>8.5635</td>\n",
       "      <td>12.7803</td>\n",
       "      <td>-1.0914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_1</th>\n",
       "      <td>11.5006</td>\n",
       "      <td>-4.1473</td>\n",
       "      <td>13.8588</td>\n",
       "      <td>5.3890</td>\n",
       "      <td>12.3622</td>\n",
       "      <td>7.0433</td>\n",
       "      <td>5.6208</td>\n",
       "      <td>16.5338</td>\n",
       "      <td>3.1468</td>\n",
       "      <td>8.0851</td>\n",
       "      <td>...</td>\n",
       "      <td>7.6421</td>\n",
       "      <td>7.7214</td>\n",
       "      <td>2.5837</td>\n",
       "      <td>10.9516</td>\n",
       "      <td>15.4305</td>\n",
       "      <td>2.0339</td>\n",
       "      <td>8.1267</td>\n",
       "      <td>8.7889</td>\n",
       "      <td>18.3560</td>\n",
       "      <td>1.9518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_2</th>\n",
       "      <td>8.6093</td>\n",
       "      <td>-2.7457</td>\n",
       "      <td>12.0805</td>\n",
       "      <td>7.8928</td>\n",
       "      <td>10.5825</td>\n",
       "      <td>-9.0837</td>\n",
       "      <td>6.9427</td>\n",
       "      <td>14.6155</td>\n",
       "      <td>-4.9193</td>\n",
       "      <td>5.9525</td>\n",
       "      <td>...</td>\n",
       "      <td>2.9057</td>\n",
       "      <td>9.7905</td>\n",
       "      <td>1.6704</td>\n",
       "      <td>1.6858</td>\n",
       "      <td>21.6042</td>\n",
       "      <td>3.1417</td>\n",
       "      <td>-6.5213</td>\n",
       "      <td>8.2675</td>\n",
       "      <td>14.7222</td>\n",
       "      <td>0.3965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_3</th>\n",
       "      <td>11.0604</td>\n",
       "      <td>-2.1518</td>\n",
       "      <td>8.9522</td>\n",
       "      <td>7.1957</td>\n",
       "      <td>12.5846</td>\n",
       "      <td>-1.8361</td>\n",
       "      <td>5.8428</td>\n",
       "      <td>14.9250</td>\n",
       "      <td>-5.8609</td>\n",
       "      <td>8.2450</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4666</td>\n",
       "      <td>4.7433</td>\n",
       "      <td>0.7178</td>\n",
       "      <td>1.4214</td>\n",
       "      <td>23.0347</td>\n",
       "      <td>-1.2706</td>\n",
       "      <td>-2.9275</td>\n",
       "      <td>10.2922</td>\n",
       "      <td>17.9697</td>\n",
       "      <td>-8.9996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_4</th>\n",
       "      <td>9.8369</td>\n",
       "      <td>-1.4834</td>\n",
       "      <td>12.8746</td>\n",
       "      <td>6.6375</td>\n",
       "      <td>12.2772</td>\n",
       "      <td>2.4486</td>\n",
       "      <td>5.9405</td>\n",
       "      <td>19.2514</td>\n",
       "      <td>6.2654</td>\n",
       "      <td>7.6784</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.4905</td>\n",
       "      <td>9.5214</td>\n",
       "      <td>-0.1508</td>\n",
       "      <td>9.1942</td>\n",
       "      <td>13.2876</td>\n",
       "      <td>-1.5121</td>\n",
       "      <td>3.9267</td>\n",
       "      <td>9.5031</td>\n",
       "      <td>17.9974</td>\n",
       "      <td>-8.8104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           var_0   var_1    var_2   var_3    var_4   var_5   var_6    var_7  \\\n",
       "ID_code                                                                       \n",
       "train_0   8.9255 -6.7863  11.9081  5.0930  11.4607 -9.2834  5.1187  18.6266   \n",
       "train_1  11.5006 -4.1473  13.8588  5.3890  12.3622  7.0433  5.6208  16.5338   \n",
       "train_2   8.6093 -2.7457  12.0805  7.8928  10.5825 -9.0837  6.9427  14.6155   \n",
       "train_3  11.0604 -2.1518   8.9522  7.1957  12.5846 -1.8361  5.8428  14.9250   \n",
       "train_4   9.8369 -1.4834  12.8746  6.6375  12.2772  2.4486  5.9405  19.2514   \n",
       "\n",
       "          var_8   var_9   ...     var_190  var_191  var_192  var_193  var_194  \\\n",
       "ID_code                   ...                                                   \n",
       "train_0 -4.9200  5.7470   ...      4.4354   3.9642   3.1364   1.6910  18.5227   \n",
       "train_1  3.1468  8.0851   ...      7.6421   7.7214   2.5837  10.9516  15.4305   \n",
       "train_2 -4.9193  5.9525   ...      2.9057   9.7905   1.6704   1.6858  21.6042   \n",
       "train_3 -5.8609  8.2450   ...      4.4666   4.7433   0.7178   1.4214  23.0347   \n",
       "train_4  6.2654  7.6784   ...     -1.4905   9.5214  -0.1508   9.1942  13.2876   \n",
       "\n",
       "         var_195  var_196  var_197  var_198  var_199  \n",
       "ID_code                                               \n",
       "train_0  -2.3978   7.8784   8.5635  12.7803  -1.0914  \n",
       "train_1   2.0339   8.1267   8.7889  18.3560   1.9518  \n",
       "train_2   3.1417  -6.5213   8.2675  14.7222   0.3965  \n",
       "train_3  -1.2706  -2.9275  10.2922  17.9697  -8.9996  \n",
       "train_4  -1.5121   3.9267   9.5031  17.9974  -8.8104  \n",
       "\n",
       "[5 rows x 200 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = train.loc[:,train.columns !='target']\n",
    "print(x.shape)\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200000,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ID_code\n",
       "train_0    0\n",
       "train_1    0\n",
       "train_2    0\n",
       "train_3    0\n",
       "train_4    0\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = train['target']\n",
    "print(y.shape)\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=scaler.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-1.1152668122349497e-15, 1.0000000000000013)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.mean(), x.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.reshape(y.shape[0],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200000, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       ...,\n",
       "       [0],\n",
       "       [0],\n",
       "       [0]], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(y.shape)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits = 5\n",
    "splits = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "splits=list(splits.split(x,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(array([     1,      2,      3, ..., 199996, 199997, 199999]),\n",
       "  array([     0,     11,     12, ..., 199988, 199992, 199998])),\n",
       " (array([     0,      1,      2, ..., 199997, 199998, 199999]),\n",
       "  array([     4,     24,     32, ..., 199993, 199994, 199996])),\n",
       " (array([     0,      1,      2, ..., 199996, 199998, 199999]),\n",
       "  array([     3,      8,     15, ..., 199979, 199980, 199997]))]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(splits))\n",
    "splits[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, valid = next(iter(splits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159999, 40001)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train), len(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-38-2772d8143820>, line 76)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-38-2772d8143820>\"\u001b[1;36m, line \u001b[1;32m76\u001b[0m\n\u001b[1;33m    base_heightclass CyclicLR(object):\u001b[0m\n\u001b[1;37m                            ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "class CyclicLR(object):\n",
    "    def __init__(self, optimizer, base_lr=1e-3, max_lr=6e-3,\n",
    "                 step_size=2000, mode='triangular', gamma=1.,\n",
    "                 scale_fn=None, scale_mode='cycle', last_batch_iteration=-1):\n",
    "\n",
    "        if not isinstance(optimizer, Optimizer):\n",
    "            raise TypeError('{} is not an Optimizer'.format(type(optimizer).__name__))\n",
    "        \n",
    "        self.optimizer = optimizer\n",
    "\n",
    "        if isinstance(base_lr, list) or isinstance(base_lr, tuple):\n",
    "            if len(base_lr) != len(optimizer.param_groups):\n",
    "                raise ValueError(\"expected {} base_lr, got {}\".format(\n",
    "                    len(optimizer.param_groups), len(base_lr)))\n",
    "            self.base_lrs = list(base_lr)\n",
    "        else:\n",
    "            self.base_lrs = [base_lr] * len(optimizer.param_groups)\n",
    "\n",
    "        if isinstance(max_lr, list) or isinstance(max_lr, tuple):\n",
    "            if len(max_lr) != len(optimizer.param_groups):\n",
    "                raise ValueError(\"expected {} max_lr, got {}\".format(\n",
    "                    len(optimizer.param_groups), len(max_lr)))\n",
    "            self.max_lrs = list(max_lr)\n",
    "        else:\n",
    "            self.max_lrs = [max_lr] * len(optimizer.param_groups)\n",
    "\n",
    "        self.step_size = step_size\n",
    "\n",
    "        if mode not in ['triangular', 'triangular2', 'exp_range'] \\\n",
    "                and scale_fn is None:\n",
    "            raise ValueError('mode is invalid and scale_fn is None')\n",
    "\n",
    "        self.mode = mode\n",
    "        self.gamma = gamma\n",
    "\n",
    "        if scale_fn is None:\n",
    "            if self.mode == 'triangular':\n",
    "                self.scale_fn = self._triangular_scale_fn\n",
    "                self.scale_mode = 'cycle'\n",
    "            elif self.mode == 'triangular2':\n",
    "                self.scale_fn = self._triangular2_scale_fn\n",
    "                self.scale_mode = 'cycle'\n",
    "            elif self.mode == 'exp_range':\n",
    "                self.scale_fn = self._exp_range_scale_fn\n",
    "                self.scale_mode = 'iterations'\n",
    "        else:\n",
    "            self.scale_fn = scale_fn\n",
    "            self.scale_mode = scale_mode\n",
    "\n",
    "        self.batch_step(last_batch_iteration + 1)\n",
    "        self.last_batch_iteration = last_batch_iteration\n",
    "\n",
    "    def batch_step(self, batch_iteration=None):\n",
    "        if batch_iteration is None:\n",
    "            batch_iteration = self.last_batch_iteration + 1\n",
    "        self.last_batch_iteration = batch_iteration\n",
    "        for param_group, lr in zip(self.optimizer.param_groups, self.get_lr()):\n",
    "            param_group['lr'] = lr\n",
    "\n",
    "    def _triangular_scale_fn(self, x):\n",
    "        return 1.\n",
    "\n",
    "    def _triangular2_scale_fn(self, x):\n",
    "        return 1 / (2. ** (x - 1))\n",
    "\n",
    "    def _exp_range_scale_fn(self, x):\n",
    "        return self.gamma**(x)\n",
    "\n",
    "    def get_lr(self):\n",
    "        step_size = float(self.step_size)\n",
    "        cycle = np.floor(1 + self.last_batch_iteration / (2 * step_size))\n",
    "        x = np.abs(self.last_batch_iteration / step_size - 2 * cycle + 1)\n",
    "\n",
    "        lrs = []\n",
    "        param_lrs = zip(self.optimizer.param_groups, self.base_lrs, self.max_lrs)\n",
    "        for param_group, base_lr, max_lr in param_lrs:\n",
    "            base_heightclass CyclicLR(object):\n",
    "    def __init__(self, optimizer, base_lr=1e-3, max_lr=6e-3,\n",
    "                 step_size=2000, mode='triangular', gamma=1.,\n",
    "                 scale_fn=None, scale_mode='cycle', last_batch_iteration=-1):\n",
    "\n",
    "        if not isinstance(optimizer, Optimizer):\n",
    "            raise TypeError('{} is not an Optimizer'.format(\n",
    "                type(optimizer).__name__))\n",
    "        self.optimizer = optimizer\n",
    "\n",
    "        if isinstance(base_lr, list) or isinstance(base_lr, tuple):\n",
    "            if len(base_lr) != len(optimizer.param_groups):\n",
    "                raise ValueError(\"expected {} base_lr, got {}\".format(\n",
    "                    len(optimizer.param_groups), len(base_lr)))\n",
    "            self.base_lrs = list(base_lr)\n",
    "        else:\n",
    "            self.base_lrs = [base_lr] * len(optimizer.param_groups)\n",
    "\n",
    "        if isinstance(max_lr, list) or isinstance(max_lr, tuple):\n",
    "            if len(max_lr) != len(optimizer.param_groups):\n",
    "                raise ValueError(\"expected {} max_lr, got {}\".format(\n",
    "                    len(optimizer.param_groups), len(max_lr)))\n",
    "            self.max_lrs = list(max_lr)\n",
    "        else:\n",
    "            self.max_lrs = [max_lr] * len(optimizer.param_groups)\n",
    "\n",
    "        self.step_size = step_size\n",
    "\n",
    "        if mode not in ['triangular', 'triangular2', 'exp_range'] \\\n",
    "                and scale_fn is None:\n",
    "            raise ValueError('mode is invalid and scale_fn is None')\n",
    "\n",
    "        self.mode = mode\n",
    "        self.gamma = gamma\n",
    "\n",
    "        if scale_fn is None:\n",
    "            if self.mode == 'triangular':\n",
    "                self.scale_fn = self._triangular_scale_fn\n",
    "                self.scale_mode = 'cycle'\n",
    "            elif self.mode == 'triangular2':\n",
    "                self.scale_fn = self._triangular2_scale_fn\n",
    "                self.scale_mode = 'cycle'\n",
    "            elif self.mode == 'exp_range':\n",
    "                self.scale_fn = self._exp_range_scale_fn\n",
    "                self.scale_mode = 'iterations'\n",
    "        else:\n",
    "            self.scale_fn = scale_fn\n",
    "            self.scale_mode = scale_mode\n",
    "\n",
    "        self.batch_step(last_batch_iteration + 1)\n",
    "        self.last_batch_iteration = last_batch_iteration\n",
    "\n",
    "    def batch_step(self, batch_iteration=None):\n",
    "        if batch_iteration is None:\n",
    "            batch_iteration = self.last_batch_iteration + 1\n",
    "        self.last_batch_iteration = batch_iteration\n",
    "        for param_group, lr in zip(self.optimizer.param_groups, self.get_lr()):\n",
    "            param_group['lr'] = lr\n",
    "\n",
    "    def _triangular_scale_fn(self, x):\n",
    "        return 1.\n",
    "\n",
    "    def _triangular2_scale_fn(self, x):\n",
    "        return 1 / (2. ** (x - 1))\n",
    "\n",
    "    def _exp_range_scale_fn(self, x):\n",
    "        return self.gamma**(x)\n",
    "\n",
    "    def get_lr(self):\n",
    "        step_size = float(self.step_size)\n",
    "        cycle = np.floor(1 + self.last_batch_iteration / (2 * step_size))\n",
    "        x = np.abs(self.last_batch_iteration / step_size - 2 * cycle + 1)\n",
    "\n",
    "        lrs = []\n",
    "        param_lrs = zip(self.optimizer.param_groups, self.base_lrs, self.max_lrs)\n",
    "        for param_group, base_lr, max_lr in param_lrs:\n",
    "            base_height = (max_lr - base_lr) * np.maximum(0, (1 - x))\n",
    "            if self.scale_mode == 'cycle':\n",
    "                lr = base_lr + base_height * self.scale_fn(cycle)\n",
    "            else:\n",
    "                lr = base_lr + base_height * self.scale_fn(self.last_batch_iteration)\n",
    "            lrs.append(lr)\n",
    "        return lrs = (max_lr - base_lr) * np.maximum(0, (1 - x))\n",
    "            if self.scale_mode == 'cycle':\n",
    "                lr = base_lr + base_height * self.scale_fn(cycle)\n",
    "            else:\n",
    "                lr = base_lr + base_height * self.scale_fn(self.last_batch_iteration)\n",
    "            lrs.append(lr)\n",
    "        return lrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_valid, y_train, y_valid = train_test_split(x,y,test_size=0.3, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((140000, 200), (60000, 200), (140000, 1), (60000, 1))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_valid.shape,y_train.shape, y_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=torch.FloatTensor(x_train)\n",
    "x_valid=torch.FloatTensor(x_valid)\n",
    "y_train=torch.FloatTensor(y_train)\n",
    "y_valid=torch.FloatTensor(y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([140000, 200]),\n",
       " torch.Size([60000, 200]),\n",
       " torch.Size([140000, 1]),\n",
       " torch.Size([60000, 1]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.size(), x_valid.size(),y_train.size(), y_valid.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data_utils.TensorDataset(x_train, y_train)\n",
    "valid = data_utils.TensorDataset(x_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(train, batch_size=20000, shuffle=True)\n",
    "validloader = torch.utils.data.DataLoader(valid, batch_size=20000, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, label =next(iter(trainloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([20000, 200]), torch.Size([20000, 1]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.size(), label.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid, label =next(iter(validloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([20000, 200]), torch.Size([20000, 1]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid.size(), label.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (fc1): Linear(in_features=200, out_features=50, bias=True)\n",
       "  (fc2): Linear(in_features=50, out_features=20, bias=True)\n",
       "  (fc3): Linear(in_features=20, out_features=1, bias=True)\n",
       "  (ac): ReLU()\n",
       "  (dr): Dropout(p=0.2)\n",
       "  (ac2): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(200, 50)\n",
    "        self.fc2 = nn.Linear(50, 20)\n",
    "        self.fc3 = nn.Linear(20, 1)\n",
    "\n",
    "\n",
    "        \n",
    "        self.ac = nn.ReLU()\n",
    "        self.dr = nn.Dropout(p=0.2)\n",
    "        self.ac2 = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.dr(self.ac(self.fc1(x)))\n",
    "        x = self.dr(self.ac(self.fc2(x)))\n",
    "        x = self.ac2(self.fc3(x))\n",
    "\n",
    "                    \n",
    "        return x\n",
    "        \n",
    "model=Model()\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0/50 train_loss:  4.262 valid_loss:  1.608 roc_auc_score:  0.595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SKTelecom\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\torch\\serialization.py:241: UserWarning: Couldn't retrieve source code for container of type Model. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "C:\\Users\\SKTelecom\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\torch\\serialization.py:241: UserWarning: Couldn't retrieve source code for container of type Model. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "C:\\Users\\SKTelecom\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\torch\\serialization.py:241: UserWarning: Couldn't retrieve source code for container of type Model. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "C:\\Users\\SKTelecom\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\torch\\serialization.py:241: UserWarning: Couldn't retrieve source code for container of type Model. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "C:\\Users\\SKTelecom\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\torch\\serialization.py:241: UserWarning: Couldn't retrieve source code for container of type Model. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5/50 train_loss:  1.781 valid_loss:  0.762 roc_auc_score:  0.848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SKTelecom\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\torch\\serialization.py:241: UserWarning: Couldn't retrieve source code for container of type Model. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "C:\\Users\\SKTelecom\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\torch\\serialization.py:241: UserWarning: Couldn't retrieve source code for container of type Model. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10/50 train_loss:  1.705 valid_loss:  0.748 roc_auc_score:  0.850\n",
      "epoch: 15/50 train_loss:  1.646 valid_loss:  0.735 roc_auc_score:  0.849\n",
      "epoch: 20/50 train_loss:  1.619 valid_loss:  0.735 roc_auc_score:  0.849\n",
      "epoch: 25/50 train_loss:  1.599 valid_loss:  0.735 roc_auc_score:  0.848\n",
      "epoch: 30/50 train_loss:  1.582 valid_loss:  0.736 roc_auc_score:  0.848\n",
      "epoch: 35/50 train_loss:  1.576 valid_loss:  0.738 roc_auc_score:  0.847\n",
      "epoch: 40/50 train_loss:  1.564 valid_loss:  0.740 roc_auc_score:  0.846\n",
      "epoch: 45/50 train_loss:  1.558 valid_loss:  0.742 roc_auc_score:  0.845\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "\n",
    "train_loss =[]\n",
    "valid_loss =[]\n",
    "roc_auc_scores =[]\n",
    "\n",
    "\n",
    "for e in range(epochs):\n",
    "   \n",
    "    running_losses = 0\n",
    "    for trains, labels in trainloader:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(trains)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_losses += loss.item()\n",
    "        \n",
    "    else:\n",
    "        valid_losses= 0\n",
    "        auc = 0\n",
    "        \n",
    "        model.eval()\n",
    "        for valids, labels in validloader:\n",
    "            ps = model(valids)\n",
    "            valid_losses += criterion(ps, labels).item()\n",
    "                \n",
    "            labels = labels.data.numpy().astype('int32')    \n",
    "            ps = ps.data.numpy()\n",
    "                \n",
    "            auc += roc_auc_score(labels, ps)\n",
    "        \n",
    "        train_loss.append(running_losses)\n",
    "        valid_loss.append(valid_losses)\n",
    "        roc_auc_scores.append(auc / (len(x_valid)/len(labels)))\n",
    "        \n",
    "        if e != 0 and max(roc_auc_scores) == roc_auc_scores[e]:\n",
    "            torch.save(model, f'../model/model_nn{roc_auc_scores[e]: .3f}_{e}.pt')\n",
    "            \n",
    "                \n",
    "\n",
    "        model.train()\n",
    "        \n",
    "        if e % 5 == 0:\n",
    "            print(f\"epoch: {e}/{epochs}\", \n",
    "                  f\"train_loss: {train_loss[e]: .3f}\",\n",
    "                  f\"valid_loss: {valid_loss[e]: .3f}\",\n",
    "                  f\"roc_auc_score: {roc_auc_scores[e]: .3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1b28b694438>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_loss, label=\"training loss\")\n",
    "plt.plot(valid_loss, label=\"validation loss\")\n",
    "plt.plot(roc_auc_scores, label=\"roc_auc_scores\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference\n",
    "\n",
    "Now that the model is trained, we can use it for inference. We've done this before, but now we need to remember to set the model in inference mode with `model.eval()`. You'll also want to turn off autograd with the `torch.no_grad()` context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.array(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=scaler.fit_transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6.021986465043483e-16, 0.9999999999999997)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.mean(), test.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=torch.FloatTensor(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_path: ../model/model_nn 0.850_7.pt\n"
     ]
    }
   ],
   "source": [
    "print(f'model_path: ../model/model_nn{max(roc_auc_scores): .3f}_{roc_auc_scores.index(max(roc_auc_scores))}.pt')\n",
    "model = torch.load(f'../model/model_nn{max(roc_auc_scores): .3f}_{roc_auc_scores.index(max(roc_auc_scores))}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "output = model(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "output=output.data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['target'] = output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200000, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_code</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_0</td>\n",
       "      <td>0.300183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_1</td>\n",
       "      <td>0.336425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_2</td>\n",
       "      <td>0.027348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test_3</td>\n",
       "      <td>0.317039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test_4</td>\n",
       "      <td>0.064108</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ID_code    target\n",
       "0  test_0  0.300183\n",
       "1  test_1  0.336425\n",
       "2  test_2  0.027348\n",
       "3  test_3  0.317039\n",
       "4  test_4  0.064108"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(submission.shape)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(f'../submission/submission_nn{roc_auc_scores[e]: .3f}_190311.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
